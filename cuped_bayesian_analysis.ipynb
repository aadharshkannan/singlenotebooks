{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec09445e-3c30-4520-9afc-72e4510aad73",
   "metadata": {},
   "source": [
    "### Bayesian CUPED (Assertions) Analysis\n",
    "\n",
    "This script reproduces the CUPED-style analysis for binary assertion data\n",
    "using the updated `stan` interface (PyStan 3) rather than the older\n",
    "`pystan` interface.  The goal is to mirror the structure of the original\n",
    "``cuped_analysis.ipynb`` while accommodating binary outcomes and\n",
    "pre/post comparisons on logical assertions.  If the `stan` package is\n",
    "available, the script will fit a hierarchical logistic model with a\n",
    "Bayesian CUPED adjustment.  When `stan` is not installed, the script\n",
    "falls back to a classical CUPED adjustment using control variates.\n",
    "\n",
    "The expected input files are two CSV or Parquet datasets with the\n",
    "columns:\n",
    "\n",
    "    - ``RunId``: an identifier for the evaluation run\n",
    "    - ``TestCaseId``: the test case identifier\n",
    "    - ``AssertionId``: the assertion identifier\n",
    "    - ``IsTrue``: binary indicator (1 if the assertion passes, 0 otherwise)\n",
    "\n",
    "The script performs the following steps:\n",
    "\n",
    "1. Reads the previous and next datasets, coercing ``IsTrue`` to binary.\n",
    "2. Produces a coverage snapshot between the two periods.\n",
    "3. Aggregates the data to compute baseline pass rates per\n",
    "   ``(TestCaseId, AssertionId)`` pair.\n",
    "4. If available, fits a Bayesian CUPED model using ``stan`` with the\n",
    "   appropriate array syntax.  Otherwise, estimates a CUPED coefficient\n",
    "   via covariance and adjusts the raw binary outcomes accordingly.\n",
    "5. Summarises per‑pair differences, produces bootstrap confidence\n",
    "   intervals, and computes variance reduction diagnostics.\n",
    "6. Generates plots analogous to those in the original notebook:\n",
    "   distribution KDEs, bootstrap distributions, and bar charts of mean\n",
    "   differences with confidence intervals.\n",
    "7. Writes summary tables and plots to an ``outputs`` directory.\n",
    "\n",
    "Note: Running the Bayesian model requires that the ``stan`` package\n",
    "be installed (PyStan ≥ 3).  If ``stan`` is not available, the code\n",
    "will still execute the classical CUPED steps and generate the plots\n",
    "accordingly.  The Stan model code uses the new array declarations:\n",
    "\n",
    "    ``array[N] int y``\n",
    "    ``array[N] int period``\n",
    "    ``array[N] int pair_id``\n",
    "    ``vector[N] x_cuped``\n",
    "\n",
    "and can be adjusted to your particular modelling needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041024ff-d108-47ef-a497-f7faf3ca5af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/stan/plugins.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import stan  # type: ignore[import]\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from statsmodels.api import OLS, add_constant\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22202f2-c8dc-479e-b1e6-b42bbcba6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these paths to point at your previous and next assertion datasets.\n",
    "PREVIOUS_PATH = Path('data/assertions_previous.csv')\n",
    "NEXT_PATH     = Path('data/assertions_next.csv')\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Number of bootstrap iterations for uncertainty quantification in the\n",
    "# classical CUPED fallback.\n",
    "N_BOOT = 10_000\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path('outputs_assertions')\n",
    "PLOT_DIR   = OUTPUT_DIR / 'plots'\n",
    "STAN_DIR   = OUTPUT_DIR / 'stan_models'\n",
    "for _dir in [OUTPUT_DIR, PLOT_DIR, STAN_DIR]:\n",
    "    _dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plotting defaults (match original notebook aesthetics)\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2699554f-0fa3-48fa-a94e-da5eeec791d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_assertion_dataset(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV or Parquet assertion dataset and coerce `IsTrue` to {0,1}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : pathlib.Path\n",
    "        The path to the dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns ``RunId``, ``TestCaseId``, ``AssertionId``\n",
    "        and ``IsTrue`` (0 or 1).\n",
    "    \"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {path}\")\n",
    "    if path.suffix.lower() == '.csv':\n",
    "        df = pd.read_csv(path)\n",
    "    elif path.suffix.lower() in {'.parquet', '.pq'}:\n",
    "        df = pd.read_parquet(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type for {path}. Use CSV or Parquet.\")\n",
    "\n",
    "    required_cols = {'RunId', 'TestCaseId', 'AssertionId', 'IsTrue'}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path} missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    # Coerce IsTrue to binary 0/1\n",
    "    if df['IsTrue'].dtype == bool:\n",
    "        df['IsTrue'] = df['IsTrue'].astype(int)\n",
    "    else:\n",
    "        def _to_binary(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            s = str(x).strip().lower()\n",
    "            if s in {'1', 'true', 't', 'yes', 'y'}:\n",
    "                return 1\n",
    "            if s in {'0', 'false', 'f', 'no', 'n'}:\n",
    "                return 0\n",
    "            try:\n",
    "                v = int(float(s))\n",
    "                return 1 if v != 0 else 0\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "        df['IsTrue'] = df['IsTrue'].map(_to_binary)\n",
    "\n",
    "    if df['IsTrue'].isna().any():\n",
    "        bad = df[df['IsTrue'].isna()].head()\n",
    "        raise ValueError(\n",
    "            f\"Non-binary values detected in 'IsTrue'. First offenders:\\n{bad}\"\n",
    "        )\n",
    "\n",
    "    return df[['RunId', 'TestCaseId', 'AssertionId', 'IsTrue']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc33e46-ef5c-481d-a4df-3c3dbcb95bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_snapshot(prev: pd.DataFrame, nxt: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute coverage statistics between previous and next datasets.\n",
    "\n",
    "    Returns a DataFrame with the number of unique (TestCaseId, AssertionId)\n",
    "    pairs in each period, the size of their intersection, and the coverage\n",
    "    rate (intersection / next).  Flags low overlap when coverage < 0.7.\n",
    "    \"\"\"\n",
    "    prev_pairs = set((prev['TestCaseId'].astype(str) + '||' + prev['AssertionId'].astype(str)))\n",
    "    next_pairs = set((nxt['TestCaseId'].astype(str) + '||' + nxt['AssertionId'].astype(str)))\n",
    "    inter_pairs = prev_pairs & next_pairs\n",
    "    coverage_rate_next = (len(inter_pairs) / len(next_pairs)) if next_pairs else np.nan\n",
    "    return pd.DataFrame({\n",
    "        'pairs_prev': [len(prev_pairs)],\n",
    "        'pairs_next': [len(next_pairs)],\n",
    "        'pairs_intersection': [len(inter_pairs)],\n",
    "        'coverage_rate_next': [coverage_rate_next],\n",
    "        'low_overlap_flag': [coverage_rate_next < 0.7 if not np.isnan(coverage_rate_next) else False]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee87002-d65a-41ba-bfc5-0000c01e075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_baseline(prev: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute baseline pass rate (mean IsTrue) for each (TestCaseId, AssertionId).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prev : pd.DataFrame\n",
    "        The previous period assertion dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns ``TestCaseId``, ``AssertionId`` and\n",
    "        ``X_baseline`` representing the baseline pass rate per pair.\n",
    "    \"\"\"\n",
    "    baseline = (prev\n",
    "                .groupby(['TestCaseId', 'AssertionId'], as_index=False)['IsTrue']\n",
    "                .mean()\n",
    "                .rename(columns={'IsTrue': 'X_baseline'}))\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac70d0d-c09e-42a7-9d66-80598f2c7fa7",
   "metadata": {},
   "source": [
    " # 1. Load the previous and next assertion datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2efdad18-b876-4cb0-a4e1-f631381c1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_df = load_assertion_dataset(PREVIOUS_PATH)\n",
    "next_df = load_assertion_dataset(NEXT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7e676-32cf-41de-a5fc-2f304e25be06",
   "metadata": {},
   "source": [
    "# 2. Coverage snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa704353-37f5-49b4-9b19-1e0a4c3e4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = coverage_snapshot(prev_df, next_df)\n",
    "baseline_df = compute_baseline(prev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268fd98-a613-4ac4-b52f-eee6119bcf04",
   "metadata": {},
   "source": [
    "# 3. STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a94e0f9-becd-4875-b75b-ac3bd516c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7c0a34467400> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7c0a34467400> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7c0a34467400> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7c0a34467400> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7c0a34467400> is already entered\n",
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7c0a34467400> is already entered\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-20' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-21' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/marshmallow/fields.py:230: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  for cls in reversed(self.__class__.__mro__):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-21' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-22' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-23' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-23' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-24' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-25' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-25' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-26' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-27' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-27' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "\u001b[32mBuilding:\u001b[0m found in cache, done.\n",
      "\u001b[36mSampling:\u001b[0m   0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stan package detected. Attempting to build and sample Bayesian model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m   0% (1/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m   1% (101/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m   3% (201/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m   4% (301/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m  12% (1000/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m  22% (1800/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m  46% (3700/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m  70% (5600/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m  86% (6900/8000)\n",
      "\u001b[1A\u001b[0J\u001b[36mSampling:\u001b[0m 100% (8000/8000)\n",
      "\u001b[1A\u001b[0J\u001b[32mSampling:\u001b[0m 100% (8000/8000), done.\n",
      "\u001b[36mMessages received during sampling:\u001b[0m\n",
      "  Gradient evaluation took 0.000325 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 3.25 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.000361 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 3.61 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.000257 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 2.57 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.00026 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 2.6 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-14' coro=<_async_in_context.<locals>.run_in_context() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-16' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/usr/lib/python3.12/abc.py:106: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-16' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-17' coro=<_async_in_context.<locals>.run_in_context() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-19' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-19' coro=<Kernel.shell_main() running at /home/aadkannan/venvs/singlenotebooks/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stan draws saved to outputs_assertions/stan_draws.parquet\n"
     ]
    }
   ],
   "source": [
    "print('stan package detected. Attempting to build and sample Bayesian model...')\n",
    "# Prepare data for Stan: aggregate counts per pair\n",
    "agg = (prev_df.groupby(['TestCaseId', 'AssertionId'], as_index=False)['IsTrue']\n",
    "       .agg(y_prev='sum', n_prev='size'))\n",
    "agg_next = (next_df.groupby(['TestCaseId', 'AssertionId'], as_index=False)['IsTrue']\n",
    "            .agg(y_next='sum', n_next='size'))\n",
    "full = agg.merge(agg_next, on=['TestCaseId', 'AssertionId'], how='outer').fillna(0)\n",
    "N_pairs = len(full)\n",
    "# Stan data using array declarations\n",
    "stan_data = {\n",
    "    'N': N_pairs,\n",
    "    'y_prev': full['y_prev'].astype(int).tolist(),\n",
    "    'n_prev': full['n_prev'].astype(int).tolist(),\n",
    "    'y_next': full['y_next'].astype(int).tolist(),\n",
    "    'n_next': full['n_next'].astype(int).tolist(),\n",
    "}\n",
    "# CUPED model code with array syntax\n",
    "stan_code_cuped = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  array[N] int<lower=0> y_prev;\n",
    "  array[N] int<lower=0> n_prev;\n",
    "  array[N] int<lower=0> y_next;\n",
    "  array[N] int<lower=0> n_next;\n",
    "}\n",
    "parameters {\n",
    "  real mu_eta;\n",
    "  real<lower=0> sigma_eta;\n",
    "  vector[N] eta_raw;\n",
    "  real tau;\n",
    "  real theta;\n",
    "}\n",
    "transformed parameters {\n",
    "  vector[N] eta = mu_eta + sigma_eta * eta_raw;\n",
    "  vector[N] q   = inv_logit(eta);\n",
    "  real qbar     = mean(q);\n",
    "  vector[N] logit_p_next = eta + tau + theta * (q - qbar);\n",
    "}\n",
    "model {\n",
    "  mu_eta    ~ normal(0, 2);\n",
    "  sigma_eta ~ normal(0, 1);\n",
    "  eta_raw   ~ std_normal();\n",
    "  tau       ~ normal(0, 1.5);\n",
    "  theta     ~ normal(0, 3);\n",
    "  y_prev ~ binomial(n_prev, q);\n",
    "  y_next ~ binomial(n_next, inv_logit(logit_p_next));\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] p_prev = q;\n",
    "  vector[N] p_next = inv_logit(logit_p_next);\n",
    "  vector[N] delta  = p_next - p_prev;\n",
    "  real overall_delta = mean(delta);\n",
    "}\n",
    "\"\"\"\n",
    "# Build and sample\n",
    "posterior = stan.build(stan_code_cuped, data=stan_data, random_seed=RANDOM_SEED)\n",
    "fit = posterior.sample(num_chains=4, num_samples=1000)\n",
    "# Extract draws to DataFrame\n",
    "stan_df = fit.to_frame()\n",
    "# Save the draws for further analysis (optional)\n",
    "stan_draws_path = OUTPUT_DIR / 'stan_draws.parquet'\n",
    "stan_df.to_parquet(stan_draws_path)\n",
    "print(f\"Stan draws saved to {stan_draws_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1ec1e-d8b6-4357-9cb1-4e618857003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic summaries to stdout\n",
    "print('\\nCoverage overview:')\n",
    "print(coverage_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0aaf8b-ed1a-4d7f-80ee-920dfde8dbaa",
   "metadata": {},
   "source": [
    "# 4. STAN Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033d799-d040-4ed5-b9de-ea7249a4f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_delta(stan_df: pd.DataFrame, plot_dir: Path = PLOT_DIR) -> Path:\n",
    "    \"\"\"\n",
    "    Plot the posterior distribution of overall_delta (mean p_next - p_prev)\n",
    "    with 95% credible interval, zero line, and annotation of P(delta > 0).\n",
    "    \"\"\"\n",
    "    if \"overall_delta\" not in stan_df.columns:\n",
    "        raise KeyError(\"Column 'overall_delta' not found in stan_df. \"\n",
    "                       \"Check fit.to_frame().columns to confirm the name.\")\n",
    "\n",
    "    draws = stan_df[\"overall_delta\"].values\n",
    "    mean = draws.mean()\n",
    "    ci_lo, ci_hi = np.percentile(draws, [2.5, 97.5])\n",
    "    p_gt0 = np.mean(draws > 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(draws, fill=True)\n",
    "    plt.axvline(0.0, color=\"black\", linestyle=\"--\", label=\"No change (0)\")\n",
    "    plt.axvline(mean, color=\"tab:blue\", linestyle=\"-\", label=f\"Posterior mean = {mean:.3f}\")\n",
    "    plt.axvline(ci_lo, color=\"tab:red\", linestyle=\"--\", label=\"95% CI\")\n",
    "    plt.axvline(ci_hi, color=\"tab:red\", linestyle=\"--\")\n",
    "\n",
    "    plt.title(\"Posterior of Overall Change (Next − Previous)\")\n",
    "    plt.xlabel(\"Overall Δ (mean pass prob, Next − Previous)\")\n",
    "    plt.ylabel(\"Posterior density\")\n",
    "\n",
    "    # Text box with summary\n",
    "    text = (\n",
    "        f\"Posterior mean Δ = {mean:.3f}\\n\"\n",
    "        f\"95% credible interval = [{ci_lo:.3f}, {ci_hi:.3f}]\\n\"\n",
    "        f\"P(Δ > 0) = {p_gt0:.3f}\"\n",
    "    )\n",
    "    plt.gca().text(\n",
    "        0.98, 0.95, text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        ha=\"right\", va=\"top\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8)\n",
    "    )\n",
    "\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    out_path = plot_dir / \"overall_delta_posterior.png\"\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b3bd2-bf4b-49b0-a261-c74b269c82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_prev_next(stan_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-draw mean pass probability across all pairs for previous and next.\n",
    "\n",
    "    Handles column names like:\n",
    "        p_prev[1], p_prev[2], ...\n",
    "        p_prev.1,  p_prev.2,  ...\n",
    "    and similarly for p_next.\n",
    "    \"\"\"\n",
    "\n",
    "    def _find_cols(base: str):\n",
    "        # Match patterns like base[1], base[2] or base.1, base.2\n",
    "        pattern = re.compile(rf\"^{base}(\\[|\\.)(\\d+)(\\])?$\")\n",
    "        cols = []\n",
    "        for c in stan_df.columns:\n",
    "            m = pattern.match(c)\n",
    "            if m:\n",
    "                # Extract index to sort later\n",
    "                idx = int(m.group(2))\n",
    "                cols.append((idx, c))\n",
    "        # Sort by index so column order aligns with pair order\n",
    "        cols_sorted = [c for _, c in sorted(cols, key=lambda x: x[0])]\n",
    "        return cols_sorted\n",
    "\n",
    "    prev_cols = _find_cols(\"p_prev\")\n",
    "    next_cols = _find_cols(\"p_next\")\n",
    "\n",
    "    if not prev_cols or not next_cols:\n",
    "        candidates = [c for c in stan_df.columns if \"p_prev\" in c or \"p_next\" in c]\n",
    "        raise KeyError(\n",
    "            \"Could not find per-pair 'p_prev'/'p_next' columns in stan_df.\\n\"\n",
    "            \"Columns containing 'p_prev' or 'p_next' were:\\n\"\n",
    "            f\"{candidates[:50]}\"\n",
    "        )\n",
    "\n",
    "    stan_df = stan_df.copy()\n",
    "    stan_df[\"mean_p_prev\"] = stan_df[prev_cols].mean(axis=1)\n",
    "    stan_df[\"mean_p_next\"] = stan_df[next_cols].mean(axis=1)\n",
    "    return stan_df\n",
    "\n",
    "\n",
    "def plot_old_vs_new_mean_pass_rate(stan_df: pd.DataFrame, plot_dir: Path = PLOT_DIR) -> Path:\n",
    "    \"\"\"\n",
    "    Violin/box style plot comparing posterior mean pass rate\n",
    "    of previous vs next system.\n",
    "    \"\"\"\n",
    "    stan_df = compute_mean_prev_next(stan_df)\n",
    "\n",
    "    long_df = pd.melt(\n",
    "        stan_df[[\"mean_p_prev\", \"mean_p_next\"]],\n",
    "        var_name=\"Period\",\n",
    "        value_name=\"mean_pass_rate\"\n",
    "    )\n",
    "    long_df[\"Period\"] = long_df[\"Period\"].map({\n",
    "        \"mean_p_prev\": \"Previous (old)\",\n",
    "        \"mean_p_next\": \"Next (new)\",\n",
    "    })\n",
    "\n",
    "    # Probability that new > old\n",
    "    diff = stan_df[\"mean_p_next\"] - stan_df[\"mean_p_prev\"]\n",
    "    p_new_gt_old = np.mean(diff > 0)\n",
    "    mean_diff = diff.mean()\n",
    "    ci_lo, ci_hi = np.percentile(diff, [2.5, 97.5])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.violinplot(\n",
    "        data=long_df,\n",
    "        x=\"Period\",\n",
    "        y=\"mean_pass_rate\",\n",
    "        inner=\"quartile\",\n",
    "        cut=0\n",
    "    )\n",
    "\n",
    "    plt.title(\"Average Assertion Pass Rate\\nPrevious vs Next (Posterior)\")\n",
    "    plt.ylabel(\"Mean pass probability\")\n",
    "    plt.xlabel(\"System\")\n",
    "\n",
    "    text = (\n",
    "        f\"Posterior mean (new − old) = {mean_diff:.3f}\\n\"\n",
    "        f\"95% CrI = [{ci_lo:.3f}, {ci_hi:.3f}]\\n\"\n",
    "        f\"P(new > old) = {p_new_gt_old:.3f}\"\n",
    "    )\n",
    "    plt.gca().text(\n",
    "        0.98, 0.05, text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        ha=\"right\", va=\"bottom\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8)\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = plot_dir / \"mean_pass_rate_old_vs_new.png\"\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad3b38-325b-4702-9126-562071687aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_pair_delta_summary(stan_df: pd.DataFrame, full_pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarise posterior delta per (TestCaseId, AssertionId) pair.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "        TestCaseId, AssertionId, delta_mean, delta_ci_lo, delta_ci_hi, prob_improved\n",
    "    \"\"\"\n",
    "    delta_cols = [c for c in stan_df.columns if c.startswith(\"delta.\")]\n",
    "    if not delta_cols:\n",
    "        raise KeyError(\"No 'delta[...'] columns found in stan_df.\")\n",
    "\n",
    "    # Sort columns so index matches pair index (1..N)\n",
    "    delta_cols_sorted = sorted(\n",
    "        delta_cols,\n",
    "        key=lambda c: int(c.split(\".\")[1])\n",
    "    )\n",
    "    deltas = stan_df[delta_cols_sorted].values  # shape: (S, N_pairs)\n",
    "\n",
    "    delta_mean = deltas.mean(axis=0)\n",
    "    delta_ci_lo = np.percentile(deltas, 2.5, axis=0)\n",
    "    delta_ci_hi = np.percentile(deltas, 97.5, axis=0)\n",
    "    prob_improved = (deltas > 0).mean(axis=0)\n",
    "\n",
    "    if len(full_pairs) != len(delta_mean):\n",
    "        raise ValueError(\"full_pairs length does not match number of delta columns.\")\n",
    "\n",
    "    summary = full_pairs[[\"TestCaseId\", \"AssertionId\"]].copy()\n",
    "    summary[\"delta_mean\"] = delta_mean\n",
    "    summary[\"delta_ci_lo\"] = delta_ci_lo\n",
    "    summary[\"delta_ci_hi\"] = delta_ci_hi\n",
    "    summary[\"prob_improved\"] = prob_improved\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def plot_top_pairs_forest(\n",
    "    stan_df: pd.DataFrame,\n",
    "    full_pairs: pd.DataFrame,\n",
    "    top_k: int = 30,\n",
    "    plot_dir: Path = PLOT_DIR\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Forest plot of the top |Δ| pairs, with 95% CrIs and P(Δ>0) annot.\n",
    "    \"\"\"\n",
    "    summary = compute_per_pair_delta_summary(stan_df, full_pairs)\n",
    "\n",
    "    # Choose top_k pairs by absolute delta_mean\n",
    "    top = summary.reindex(summary[\"delta_mean\"].abs().sort_values(ascending=False).index)\n",
    "    top = top.head(top_k).copy()\n",
    "    top[\"label\"] = top[\"TestCaseId\"].astype(str) + \"::\" + top[\"AssertionId\"].astype(str)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, max(6, 0.3 * len(top))))\n",
    "    y_positions = np.arange(len(top))\n",
    "\n",
    "    plt.errorbar(\n",
    "        x=top[\"delta_mean\"],\n",
    "        y=y_positions,\n",
    "        xerr=[\n",
    "            top[\"delta_mean\"] - top[\"delta_ci_lo\"],\n",
    "            top[\"delta_ci_hi\"] - top[\"delta_mean\"]\n",
    "        ],\n",
    "        fmt=\"o\",\n",
    "        color=\"tab:blue\",\n",
    "        ecolor=\"black\",\n",
    "        capsize=3\n",
    "    )\n",
    "    plt.axvline(0.0, color=\"black\", linestyle=\"--\")\n",
    "    plt.yticks(y_positions, top[\"label\"])\n",
    "    plt.xlabel(\"Δ (p_next − p_prev)\")\n",
    "    plt.title(f\"Top {len(top)} Assertions by |Posterior Mean Δ|\")\n",
    "\n",
    "    # Annotate prob_improved per point on the right\n",
    "    for y, p in zip(y_positions, top[\"prob_improved\"]):\n",
    "        plt.text(\n",
    "            x=plt.gca().get_xlim()[1],\n",
    "            y=y,\n",
    "            s=f\"P(Δ>0)={p:.2f}\",\n",
    "            va=\"center\",\n",
    "            ha=\"right\",\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = plot_dir / \"top_pairs_forest.png\"\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe03552-7bf0-4430-8925-f33b4598bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_df = fit.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df61d3-551d-4cc9-ad6a-ae684538e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_path = plot_overall_delta(stan_df)\n",
    "mean_rate_path = plot_old_vs_new_mean_pass_rate(stan_df)\n",
    "forest_path = plot_top_pairs_forest(stan_df, full, top_k=30)\n",
    "\n",
    "print(\"Key plots:\")\n",
    "print(\"  Overall delta posterior:\", overall_path)\n",
    "print(\"  Mean pass rate old vs new:\", mean_rate_path)\n",
    "print(\"  Top per-pair changes (forest):\", forest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUPED Assertions (PyStan)",
   "language": "python",
   "name": "cuped_assertions_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
